{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9XkX8Gzl+p8ex/5PiRjCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajithvernekar/recommender-system-e-commerce/blob/main/Code/DataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class is to generate and sample the data from various metadata and review files."
      ],
      "metadata": {
        "id": "vCro1HjKI3Ks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iXXyA6A7Acjq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator:\n",
        "  def __init__(self, meta_files_dir, review_files_dir):\n",
        "    self.meta_files_dir = meta_files_dir\n",
        "    self.review_files_dir = review_files_dir\n",
        "\n",
        "  def read_metadata(self, file):\n",
        "    ### load the meta data\n",
        "    data = []\n",
        "    with gzip.open(filename=file) as f:\n",
        "        for l in f:\n",
        "            data.append(json.loads(l.strip()))\n",
        "\n",
        "    # convert list into pandas dataframe\n",
        "    df = pd.DataFrame.from_dict(data)\n",
        "    df = df[['asin', 'title', 'brand']]\n",
        "    df = df.rename(columns={'asin':'item_id'})\n",
        "\n",
        "    return df\n",
        "\n",
        "  def read_reviewsdata(self, file):\n",
        "    # Load the reviews data\n",
        "    data = []\n",
        "    with gzip.open(filename=file) as f:\n",
        "        for l in f:\n",
        "            data.append(json.loads(l.strip()))\n",
        "\n",
        "    # Convert list into pandas dataframe\n",
        "    df = pd.DataFrame.from_dict(data)\n",
        "    df = df[['asin', 'reviewerID', 'overall', 'reviewTime']]\n",
        "    df = df.rename(columns={'asin':'item_id', 'reviewerID':'user_id',\n",
        "                            'overall':'rating', 'reviewTime':'timestamp'})\n",
        "\n",
        "    # Add sub_cat column with file name without extension\n",
        "    file_name = os.path.basename(file)\n",
        "    sub_cat = file_name.split('.')[0]\n",
        "    df['sub_cat'] = sub_cat\n",
        "\n",
        "    # Add main_cat column based on sub_cat\n",
        "    df['main_cat'] = ''\n",
        "    df.loc[df['sub_cat'].isin(['All_Beauty', 'AMAZON_FASHION',\n",
        "                                'Luxury_Beauty']), 'main_cat'] = 'Beauty and Fashion'\n",
        "    df.loc[df['sub_cat'].isin(['Software', 'Video_Games', 'Electronics', 'Kindle_Store',\n",
        "                                'Cell_Phones_and_Accessories']), 'main_cat'] = 'Electronics and Technology'\n",
        "    df.loc[df['sub_cat'].isin(['Digital_Music', 'Magazine_Subscriptions',\n",
        "                                'Movies_and_TV']), 'main_cat'] = 'Media and Entertainment'\n",
        "\n",
        "    return df\n",
        "\n",
        "  def merge_and_sample_data(self, metadata, reviewsdata):\n",
        "    df = pd.merge(metadata, reviewsdata, on='item_id', how='right')\n",
        "    df = df.sample(n=10000, random_state=42)\n",
        "    return df\n",
        "\n",
        "  def generate_data(self, meta_files, review_files):\n",
        "    merged_dfs = []\n",
        "\n",
        "    # Process each meta file and review file\n",
        "    for meta_file, review_file in zip(meta_files, review_files):\n",
        "        # Read metadata\n",
        "        df1 = self.read_metadata(os.path.join(self.meta_files_dir, meta_file))\n",
        "        # Read reviews data\n",
        "        df2 = self.read_reviewsdata(os.path.join(self.review_files_dir, review_file))\n",
        "        # Merge DataFrames\n",
        "        merged_df = self.merge_and_sample_data(df1, df2)\n",
        "        # Append merged DataFrame to the list\n",
        "        merged_dfs.append(merged_df)\n",
        "\n",
        "    # Concatenate all merged DataFrames into a single DataFrame\n",
        "    df = pd.concat(merged_dfs, ignore_index=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "vPOmlIqMBlcN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_files_dir = '../Data/metaFiles/'\n",
        "review_files_dir = '../Data/reviewFiles/'\n",
        "\n",
        "meta_files = ['meta_All_Beauty.json.gz', 'meta_AMAZON_FASHION.json.gz', 'meta_Luxury_Beauty.json.gz']\n",
        "review_files = ['All_Beauty.json.gz', 'AMAZON_FASHION.json.gz', 'Luxury_Beauty.json.gz',\n",
        "                'Software.json.gz', 'Video_Games.json.gz', 'Electronics.json.gz', 'Kindle_Store.json.gz', 'Cell_Phones_and_Accessories.json.gz',\n",
        "                'Digital_Music.json.gz', 'Magazine_Subscriptions.json.gz', 'Movies_and_TV.json.gz']\n",
        "\n",
        "# Data generation\n",
        "data_generator = DataGenerator(meta_files_dir, review_files_dir)\n",
        "data = data_generator.generate_data(meta_files, review_files)"
      ],
      "metadata": {
        "id": "hD9vxBJOFmM5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ersqg-lFx7u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}